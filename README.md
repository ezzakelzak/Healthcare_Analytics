![Azure](https://img.shields.io/badge/Azure-Cloud-blue?logo=microsoft-azure&style=flat-square)
![PySpark](https://img.shields.io/badge/PySpark-Big%20Data-orange?logo=apache-spark&style=flat-square)
![Azure Data Factory](https://img.shields.io/badge/Azure-Data%20Factory-blue?logo=microsoft-azure&style=flat-square)
![Azure Synapse](https://img.shields.io/badge/Azure-Synapse%20Analytics-blue?logo=microsoft-azure&style=flat-square)
![Python](https://img.shields.io/badge/Python-3.9+-yellow?logo=python&style=flat-square)
![Databricks](https://img.shields.io/badge/Databricks-PySpark-red?logo=databricks&style=flat-square)
![PowerBI](https://img.shields.io/badge/Power%20BI-Dashboard-orange?logo=power-bi&style=flat-square)
![Git](https://img.shields.io/badge/Git-CI%2FCD-green?logo=git&style=flat-square)



ğŸ“‘ Table des matiÃ¨res

ğŸ“Œ PrÃ©sentation du projet

ğŸ¯ Objectifs

ğŸ“‚ Structure du projet

ğŸ› ï¸ Outils et technologies

ğŸ“ Architecture des donnÃ©es

â­ ModÃ¨le en Ã©toile (Star Schema)

âš™ï¸ Mise en Å“uvre Ã©tape par Ã©tape

1. Configuration dâ€™Event Hub

2. Simulation des donnÃ©es

3. Configuration du stockage

4. Traitement avec Databricks

5. Pool SQL Synapse

ğŸ“Š Analyse de donnÃ©es

ğŸ“Œ PrÃ©sentation du projet

Ce projet prÃ©sente une pipeline de data engineering en temps rÃ©el appliquÃ©e au secteur de la santÃ©, visant Ã  analyser le flux des patients Ã  travers les services hospitaliers grÃ¢ce aux services cloud Azure.
La pipeline collecte les donnÃ©es en continu, les traite avec Databricks (PySpark), et les stocke dans Azure Synapse SQL Pool pour lâ€™analyse et la visualisation.

Partie 1 â€“ Data Engineering : crÃ©ation du pipeline dâ€™ingestion et de transformation en temps rÃ©el.
Partie 2 â€“ Analyse : connexion de Synapse Ã  Power BI et conception dâ€™un tableau de bord interactif pour les indicateurs clÃ©s hospitaliers.


ğŸ—ï¸ Pipeline
<img src="images/Architecture.png" alt="Architecture" width="800"/>

ğŸ¯ Objectifs

Collecter des donnÃ©es patients en temps rÃ©el via Azure Event Hub.

Nettoyer et transformer les donnÃ©es avec Databricks (couches Bronze â†’ Silver â†’ Gold).

Mettre en place un modÃ¨le en Ã©toile dans Synapse SQL Pool pour des requÃªtes efficaces.

Assurer la gestion de version avec Git.

ğŸ“‚ Structure du projet

â”œâ”€â”€ databricks-notebooks/     # Notebooks de transformation
â”‚   â”œâ”€â”€ 01_bronze_rawdata.py
â”‚   â”œâ”€â”€ 02_silver_cleandata.py
â”‚   â””â”€â”€ 03_gold_transform.py
â”œâ”€â”€ simulator/                # Scripts de simulation de donnÃ©es
â”‚   â””â”€â”€ patient_flow_generator.py
â”œâ”€â”€ sqlpool-quries/           # Scripts SQL pour Synapse
â”‚   â””â”€â”€ SQL_pool_quries.sql
â””â”€â”€ README.md                 # Documentation du projet

ğŸ› ï¸ Outils et technologies

Azure Event Hub â€“ Ingestion de donnÃ©es en temps rÃ©el

Azure Databricks â€“ Traitement ETL basÃ© sur PySpark

Azure Data Lake Storage â€“ Stockage des donnÃ©es brutes et nettoyÃ©es

Azure Synapse SQL Pool â€“ EntrepÃ´t de donnÃ©es pour lâ€™analyse

Power BI â€“ Visualisation et tableau de bord

Python 3.9+ â€“ Langage principal

ğŸ“ Architecture des donnÃ©es

La pipeline suit une architecture multi-couches :

Couche Bronze : DonnÃ©es brutes JSON issues dâ€™Event Hub, stockÃ©es dans ADLS.

Couche Silver : DonnÃ©es nettoyÃ©es et structurÃ©es (validation des types, gestion des valeurs nulles).

Couche Gold : DonnÃ©es agrÃ©gÃ©es et prÃªtes Ã  Ãªtre utilisÃ©es dans Power BI.

â­ ModÃ¨le en Ã©toile (Star Schema)

Les donnÃ©es de la couche Gold dans Synapse suivent un modÃ¨le en Ã©toile pour optimiser lâ€™analyse :

Table de faits : FactPatientFlow (visites des patients, temps dâ€™attente, sortie, etc.)

Tables de dimensions :

DimDepartment â€“ Informations sur les services

DimPatient â€“ DonnÃ©es dÃ©mographiques des patients

DimTime â€“ Dimension temporelle

âš™ï¸ Mise en Å“uvre Ã©tape par Ã©tape
1. Configuration dâ€™Event Hub

CrÃ©ation dâ€™un namespace Event Hub et dâ€™un hub â€œpatient-flowâ€.

Configuration des groupes de consommateurs pour le streaming Databricks.

2. Simulation des donnÃ©es

DÃ©veloppement du script Python patient_flow_generator.py pour gÃ©nÃ©rer des donnÃ©es fictives (services, temps dâ€™attente, statut de sortie) et les envoyer Ã  Event Hub.

Code du producteur

3. Configuration du stockage

Mise en place de Azure Data Lake Storage (ADLS Gen2).

CrÃ©ation des conteneurs pour les couches bronze, silver, et gold.

4. Traitement avec Databricks

Notebook 1
 : lecture du flux Event Hub dans la couche Bronze.

Notebook 2
 : nettoyage et validation du schÃ©ma.

Notebook 3
 : agrÃ©gation et crÃ©ation des tables du modÃ¨le en Ã©toile.

5. Pool SQL Synapse

CrÃ©ation dâ€™un pool SQL dÃ©diÃ© dans Azure Synapse.

ExÃ©cution des scripts SQL pour les tables de faits et de dimensions :

Scripts DDL


ğŸ“Š Analyse de donnÃ©es

Une fois la pipeline de donnÃ©es Ã©tablie et le modÃ¨le en Ã©toile implÃ©mentÃ© dans Synapse SQL Pool, la derniÃ¨re Ã©tape consiste Ã  crÃ©er un tableau de bord interactif dans Power BI.

ğŸ”— Connexion Synapse â†’ Power BI

Connexion du pool SQL Synapse Ã  Power BI via une connexion SQL directe.

Importation des tables FactPatientFlow et Dimensions.

CrÃ©ation des relations pour le reporting basÃ© sur le modÃ¨le en Ã©toile.

ğŸ“ˆ FonctionnalitÃ©s du tableau de bord

Le tableau de bord fournit des indicateurs sur :

Le taux dâ€™occupation des lits par service et par genre.

Les tendances du flux de patients (admissions, temps dâ€™attente).

durÃ©e de sÃ©jour, nombre total de patients ....


âœ… RÃ©sultats clÃ©s

Pipeline complÃ¨te : de lâ€™ingestion en temps rÃ©el jusquâ€™Ã  la visualisation analytique.

Architecture scalable : facilement adaptable Ã  dâ€™autres jeux de donnÃ©es hospitaliers.

Valeur mÃ©tier : permet aux administrateurs dâ€™hÃ´pitaux de suivre lâ€™utilisation des lits, le flux des patients et lâ€™efficacitÃ© des services.

<img src="images/Dashboard.png" alt="Architecture" width="800"/>